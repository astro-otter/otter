{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eafa62fc-d094-49b9-8d77-5414b87b52b8",
   "metadata": {},
   "source": [
    "# Reformat the original JSON files given to me for upload \n",
    "This notebook reformats and combines the TDE radio data that I got from Collin to put in the database. This reformats into the new form shown in the schema document!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ddf23206-a311-40c7-9e20-29d9a548d542",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import json\n",
    "import uuid\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "54750331-4f24-4434-a756-dc7eb08ab1fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_disc_map = {\n",
    "    'AT2022cmc': 59621.45,\n",
    "    'AT2020vwl': 59132.73,\n",
    "    'ASASSN-15oi' : 57248.2,\n",
    "    'XMMSL1 J0740-85': 56748,\n",
    "    'AT2019azh' : 58536.02,\n",
    "    'Sw J1644+57': 55648.54,\n",
    "    'AT2018hyz':  58428.64,\n",
    "    'AT2019dsg': 58582.46,\n",
    "    'IGR J12580+0134' : 55572,\n",
    "    'ASASSN-14li': 56983,\n",
    "    'AT2020opy' : 59038.23\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "467523b4-a05e-4ff0-a8da-f5437b7a8e75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jsonpath = '/home/nfranz/backup-base-data/'\n",
    "jsons = glob.glob(jsonpath+'*.json')\n",
    "\n",
    "for j in jsons:\n",
    "    with open(j, 'r') as s:\n",
    "        data = json.load(s)[0]\n",
    "\n",
    "    # get names organized\n",
    "    names = [data['name']]\n",
    "    nameRefs = []\n",
    "    for name in names:\n",
    "        if 'AT' in name:\n",
    "            nameRefs.append('TNS')\n",
    "        elif 'Sw' in name:\n",
    "            nameRefs.append('Swift')\n",
    "        elif 'XMM' in name:\n",
    "            nameRefs.append('XMM-Newton')\n",
    "        elif 'CNSS' in name:\n",
    "            nameRefs.append('CNSS')\n",
    "        elif 'ASASSN' in name:\n",
    "            nameRefs.append('ASASSN')\n",
    "        elif 'IGR' in name:\n",
    "            nameRefs.append('IGR')\n",
    "    \n",
    "    # get coordinates organized\n",
    "    coords = [(ra['value'], dec['value']) for ra, dec in zip(data['ra'], data['dec'])]\n",
    "    units = [('hourangle', 'deg') for i in range(len(data['ra']))]\n",
    "    sources = [source['bibcode'] for source in data['sources']]\n",
    "    default = [False]*len(data['ra'])\n",
    "    default[0] = True\n",
    "    uuids = [uuid.uuid4() for i in range(len(data['ra']))]\n",
    "    galactic = SkyCoord(coords, unit=(u.hourangle, u.deg), frame='icrs').galactic\n",
    "\n",
    "    # get redshifts\n",
    "    zs = [z['value'] for z in data['z']]\n",
    "    \n",
    "    # define the general info schema\n",
    "    schema = {\n",
    "         \"schema_version\": {\"value\":'0',\n",
    "                    'comment': 'Original Dataset'\n",
    "                    },\n",
    "        \"name\": {'default_name': data['name'],\n",
    "                 'alias': [{'value': name, 'reference':ref} for name, ref in zip(names, nameRefs)]\n",
    "                },\n",
    "        \"coordinate\": {\"equitorial\": [{'ra': coord[0], \n",
    "                                       'dec': coord[1], \n",
    "                                       'epoch': 'J2000',\n",
    "                                       'system': 'ICRS',\n",
    "                                       'ra_units': unit[0],\n",
    "                                       'dec_units': unit[1],\n",
    "                                       'reference': sources,\n",
    "                                       'computed': False,\n",
    "                                       'default': defa,\n",
    "                                       'uuid': str(uu)\n",
    "                                       } for coord, unit, defa, uu in zip(coords, units, default, uuids)],\n",
    "                       \"galactic\": [{'l': float(row.l.value),\n",
    "                                     'b': float(row.b.value),\n",
    "                                     'l_units': 'deg',\n",
    "                                     'b_units': 'deg',\n",
    "                                     'reference': str(uu),\n",
    "                                     'computed': True\n",
    "                                    } for row, uu in zip(galactic, uuids)]\n",
    "                      },\n",
    "        \"distance\": {'redshift': [{'value': z,\n",
    "                                   'reference': sources,\n",
    "                                   'computed': False,\n",
    "                                  } for z in zs]\n",
    "                    },     \n",
    "        \"classification\": [{\n",
    "            'object_class': 'TDE',\n",
    "            'confidence': 1.0,\n",
    "            'reference': sources,\n",
    "            'default': True\n",
    "        }],\n",
    "        \n",
    "        'reference_alias': [{\"name\":src['bibcode'],\n",
    "                             \"human_readable_name\":src['name']\n",
    "                            } for src in data['sources'] \n",
    "                           ],\n",
    "        \n",
    "        \n",
    "        \n",
    "         }\n",
    "    \n",
    "    # epoch info if available\n",
    "    if 't_disc' in data:\n",
    "        schema['epoch'] = {'date_discovery':[{\"value\":date['value'],\n",
    "                                              \"date_format\":\"MJD\", \n",
    "                                              \"reference\": sources,\n",
    "                                              \"computed\": False}\n",
    "                                            ] for date in data['t_disc']}\n",
    "    else:\n",
    "        schema['epoch'] = {'date_discovery':[{\"value\":t_disc_map[names[0]],\n",
    "                                              \"date_format\":\"MJD\", \n",
    "                                              \"reference\": sources,\n",
    "                                              \"computed\": False}\n",
    "                                            ]}\n",
    "    \n",
    "    # add in the photometry\n",
    "    schema['photometry'] = {}\n",
    "    \n",
    "    ## first find the different sources\n",
    "    photsources = {}\n",
    "    for photo in data['photometry']['radio']:\n",
    "        if photo['source'] not in photsources:\n",
    "            \n",
    "            alias = str(photo['source'])\n",
    "            if alias == 'unknown':\n",
    "                photsources[alias] = sources\n",
    "            # get the bibcode\n",
    "            for src in data['sources']:\n",
    "                if src['alias'] == alias:\n",
    "                    # put in the source mapping\n",
    "                    photsources[alias] = src['bibcode']\n",
    "                    break     \n",
    "                    \n",
    "    #print(photsources)\n",
    "                    \n",
    "    ## then iterate over the possible sources and find all photometry values with that\n",
    "    i = 0\n",
    "    samplephot = {}\n",
    "    for alias, bibcode in photsources.items():\n",
    "        for photo in data['photometry']['radio']:\n",
    "            if photo['source'] == alias:\n",
    "                name = f'phot_{i}'\n",
    "                if name not in schema['photometry']:\n",
    "                    schema['photometry'][name] = {'reference':bibcode,\n",
    "                                                  'data': []}\n",
    "                    samplephot[name] = []\n",
    "                \n",
    "                samplephot[name].append(photo)\n",
    "        i += 1\n",
    "    \n",
    "    filteraliases = []\n",
    "    for phot in samplephot:\n",
    "        schema['photometry'][phot]['data'] = []\n",
    "        for point in samplephot[phot]:\n",
    "            \n",
    "            if 'nu_GHz' in data:\n",
    "                filteralias = data['nu_GHz'][0]['value'] + 'GHz'\n",
    "            else: # it's in the individual photometry\n",
    "                filteralias = str(point['nu_GHz']) + 'GHz'\n",
    "                \n",
    "            if filteralias not in filteraliases:\n",
    "                filteraliases.append(filteralias)\n",
    "            \n",
    "            inpoint = {'fluxdensity': point['F_mJy'],\n",
    "                       'fluxdensity_units': 'mJy',\n",
    "                       'date_format': 'MJD',\n",
    "                       'filter_key': filteralias\n",
    "                       }\n",
    "            \n",
    "            if point['t_MJD'] is not None :\n",
    "                inpoint['date'] = point['t_MJD']\n",
    "            else:\n",
    "                mjd = t_disc_map[names[0]] + point['dt_days']\n",
    "                inpoint['date'] = mjd\n",
    "            \n",
    "            schema['photometry'][phot]['data'].append(inpoint)\n",
    "            \n",
    "    # add a filter_alias property\n",
    "    schema['filter_alias'] = []\n",
    "    for filtername in filteraliases:\n",
    "        forSchema = {'filter_key': filtername,\n",
    "                     'freq_eff': float(filtername.replace('GHz', '')),\n",
    "                     'freq_units': 'GHz'\n",
    "                    }\n",
    "        schema['filter_alias'].append(forSchema)\n",
    "        \n",
    "            \n",
    "    out = json.dumps(schema, indent=4)\n",
    "    out = '[' + out\n",
    "    out += ']'\n",
    "    # print(out)\n",
    "    outpath = f'/home/nfranz/otter/data/base/{os.path.basename(j)}'\n",
    "    with open(outpath, 'w') as outfile:\n",
    "        outfile.write(out)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c3fd70-e2ec-4477-ba4f-f50119596571",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
