{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ecd6949-72d9-40ae-969c-0b0234dc4d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import os\n",
    "import pandas as pd\n",
    "from otter import Otter\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d8bd90-5b8d-4cf9-adc9-b65edb266622",
   "metadata": {},
   "source": [
    "# Testing upload_zip\n",
    "Use caution running this so we don't exceed the ADS query limits!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "154a5c04-6a58-4247-b909-f2d2a90302aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipfile = os.path.join(os.path.dirname(os.getcwd()), 'data', 'test-zip.zip')\n",
    "datadir = os.path.join(os.path.dirname(os.getcwd()), 'data')\n",
    "datapath = os.path.join(datadir, os.path.basename(zipfile).replace('.zip', ''))\n",
    "\n",
    "with ZipFile(zipfile) as z:\n",
    "    z.extractall(datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99764435-9d8b-4b74-8246-9e4cf3e371bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Otter(username='admin@otter', password='insecure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b242f2b9-75a0-450b-86e2-c2016440e428",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding this as a new object...\n"
     ]
    }
   ],
   "source": [
    "db.upload_zip(zipfile, testing=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6976d13f-4cec-454b-9dd8-65d01135a57f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Testing merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de3796c-352d-439a-bb4a-b014d6a64680",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from otter import Otter, Transient\n",
    "from copy import deepcopy\n",
    "from collections import Counter\n",
    "import awkward as ak\n",
    "import warnings\n",
    "import numpy as np\n",
    "import re\n",
    "from astropy.coordinates import SkyCoord\n",
    "import json\n",
    "\n",
    "# generate some test cases\n",
    "db = Otter()\n",
    "t1 = db.query(names='2022xkq')[0] # \n",
    "t2 = deepcopy(t1)\n",
    "print(t1.keys())\n",
    "\n",
    "# change t2 for testing\n",
    "t2['name'] = {'default_name':'2022xkq',\n",
    "             'alias': [{'value':'foo', 'reference': 'x'},\n",
    "                      {'value': '2022xkq', 'reference': 'x'}]}\n",
    "t2['reference_alias'].append({'name': 'x',\n",
    "   'human_readable_name': 'test, name (year)'}) # add an extra value\n",
    "del t2['photometry']\n",
    "t2['for_test'] = {'test': 'bar'} # add a test key that isn't in t1\n",
    "t2['coordinate/equitorial'][0]['reference'] = 'noah'\n",
    "t2['filter_alias'].append({'filter_key': 'foo'})\n",
    "t2['schema_version/value'] = 100\n",
    "t2['epoch'] = {'date_peak': [{'value': 56983,\n",
    "    'date_format': 'MJD',\n",
    "    'reference': ['2016ApJ...819L..25A',\n",
    "     '2016Sci...351...62V',\n",
    "     '2016ApJ...832L..10R',\n",
    "     '2018MNRAS.475.4011B'],\n",
    "    'computed': False}],\n",
    "               \n",
    "               'date_discovery': [{'value': 56983,\n",
    "    'date_format': 'MJD',\n",
    "    'reference': ['2016ApJ...819L..25A',\n",
    "     '2016Sci...351...62V',\n",
    "     '2016ApJ...832L..10R',\n",
    "     '2018MNRAS.475.4011B'],\n",
    "    'computed': False}],\n",
    "               \n",
    "               \n",
    "              'date_discovery': [{'value': 56984,\n",
    "    'date_format': 'MJD',\n",
    "    'reference': ['2016ApJ...819L..25A',\n",
    "     '2016Sci...351...62V',\n",
    "     '2016ApJ...832L..10R',\n",
    "     '2018MNRAS.475.4011B'],\n",
    "    'computed': False}]\n",
    "              }\n",
    "\n",
    "t2['distance'] = {\n",
    "    \"redshift\": [\n",
    "      {\n",
    "        \"value\": \"0.0207\",\n",
    "        \"reference\": [\n",
    "          \"Noah\"\n",
    "        ],\n",
    "        \"computed\": False\n",
    "      },\n",
    "        {\n",
    "        \"value\": \"0.02\",\n",
    "        \"reference\": [\n",
    "          \"Noah\"\n",
    "        ],\n",
    "        \"computed\": False\n",
    "      }\n",
    "    ],\n",
    "    \n",
    "    \"dispersion_measure\": [\n",
    "      {\n",
    "        \"value\": \"0.0206\",\n",
    "        \"reference\": [\n",
    "          \"Noah\"\n",
    "        ],\n",
    "        \"computed\": False\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "  \n",
    "t2['classification'] = [{'object_class':'SN',\n",
    "                        'confidence': 1,\n",
    "                         'reference': 'Noah'\n",
    "                        }]\n",
    "    \n",
    "t2['photometry'] = {'phot_0': {'telescope': 'Noahs Telescope',\n",
    "                               'reference': 'Noah',\n",
    "                               'flux': [{'filter': 'z',\n",
    "                                 'telescope': 'Noahs Telescope',\n",
    "                                 'upperlimit': True,\n",
    "                                 'date': 59864.4914116667,\n",
    "                                 'date_format': 'MJD',\n",
    "                                 'raw': 20.01,\n",
    "                                 'raw_units': 'mag(AB)',\n",
    "                                 'filter_key': 'NoahsTelescope.z',\n",
    "                                 'obs_type': 'uvoir'}]},\n",
    "                    'phot_1': {'telescope': 'CAHA',\n",
    "                               'reference': 'Noah',\n",
    "                               'flux': [{'filter': 'H',\n",
    "                                 'telescope': 'CAHA',\n",
    "                                 'upperlimit': False,\n",
    "                                 'date': 59898.12077,\n",
    "                                 'date_format': 'MJD',\n",
    "                                 'raw': 14.87048,\n",
    "                                 'raw_err': 0.0187,\n",
    "                                 'raw_units': 'mag(AB)',\n",
    "                                 'filter_key': 'CAHA.H',\n",
    "                                 'obs_type': 'uvoir'}]}\n",
    "            \n",
    "                               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9504ca8-4a8d-4c24-91fe-451cf40f63ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(json.dumps(dict(t2 + t1), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657a80a1-5994-4b4d-a3c0-6467054ae58e",
   "metadata": {},
   "source": [
    "# Testing upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2041740e-178e-4d9d-9341-8bbe8ffce677",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db = Otter(username='admin@otter', password='insecure')\n",
    "db.upload(t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81f14d2-b0e4-44c7-abaf-b2d48d2df835",
   "metadata": {},
   "source": [
    "# EVERYTHING BELOW THIS LINE WAS JUST FOR DEVELOPMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697ed9ea-8c33-45b7-8e1e-2914a0426f17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _merge_names(t1, t2, out):\n",
    "    '''\n",
    "    Private method to merge the name data in t1 and t2 and put it in out\n",
    "    '''\n",
    "    key = 'name'\n",
    "    out[key] = {}\n",
    "        \n",
    "    # first deal with the default_name key\n",
    "    # we are gonna need to use some regex magic to choose a preferred default_name\n",
    "    if t1[key]['default_name'] == t2[key]['default_name']:\n",
    "        out[key]['default_name'] = t1[key]['default_name']\n",
    "    else:\n",
    "        # we need to decide which default_name is better\n",
    "        # it should be the one that matches the TNS style\n",
    "        # let's use regex\n",
    "        n1 = t1[key]['default_name']\n",
    "        n2 = t2[key]['default_name']\n",
    "\n",
    "        # write some discriminating regex expressions\n",
    "        exp1 = '^[0-9]' # starts with a number, this is preferred because it is TNS style\n",
    "        exp2 = '.$' # ends with any character, this is also preferred because it is TNS style\n",
    "        exp3 = '^[0-9]{3}' # checks if first four characters are a number, like a year :), this is pretty strict though\n",
    "        exp4 = '^AT' # checks if it starts with AT like TNS names\n",
    "        exps = [exp1, exp2, exp3, exp4]\n",
    "\n",
    "        # score each default_name based on this\n",
    "        score1 = 0\n",
    "        score2 = 0\n",
    "        for e in exps:\n",
    "            re1 = re.findall(e, n1)\n",
    "            re2 = re.findall(e, n2)\n",
    "            if re1:\n",
    "                score1 += 1\n",
    "            if re2:\n",
    "                score2 += 1\n",
    "\n",
    "        # assign a default_name based on the score\n",
    "        if score1 > score2: \n",
    "            out[key]['default_name'] = t1[key]['default_name']\n",
    "        elif score2 > score1:\n",
    "            out[key]['default_name'] = t2[key]['default_name']\n",
    "        else:\n",
    "            warnings.warn('Names have the same score! Just using the existing default_name')\n",
    "            out[key]['default_name'] = t1[key]['default_name']\n",
    "\n",
    "    # now deal with aliases\n",
    "    # create a reference mapping for each\n",
    "    t1map = {}\n",
    "    for val in t1[key]['alias']:\n",
    "        ref = val['reference']\n",
    "        if isinstance(ref, str):\n",
    "            t1map[val['value']] = [ref]\n",
    "        else:\n",
    "            t1map[val['value']] = [ref]\n",
    "\n",
    "    t2map = {}\n",
    "    for val in t2[key]['alias']:\n",
    "        ref = val['reference']\n",
    "        if isinstance(ref, str):\n",
    "            t2map[val['value']] = [ref]\n",
    "        else:\n",
    "            t2map[val['value']] = [ref]\n",
    "\n",
    "    # figure out which ones we need to be careful with references in        \n",
    "    inboth = list(t1map.keys() & t2map.keys()) # in both so we'll have to merge the reference key\n",
    "    int1 = list(t1map.keys() - t2map.keys()) # only in t1\n",
    "    int2 = list(t2map.keys() - t1map.keys()) # only in t2\n",
    "\n",
    "    # add ones that are not in both first, these are easy\n",
    "    L1 = [{'value':k, 'reference':t1map[k]} for k in int1]\n",
    "    L2 = [{'value':k, 'reference':t2map[k]} for k in int2]\n",
    "    Lboth = [{'value':k, 'reference':t1map[k]+t2map[k]} for k in inboth]\n",
    "    out[key]['alias'] =  L1+L2+Lboth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4f46fb-c355-4dce-8db0-89ddc6af8964",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _merge_coords(t1, t2, out):\n",
    "    '''\n",
    "    Merge the coordinates subdictionaries for t1 and t2 and put it in out\n",
    "    '''\n",
    "    key = 'coordinate'\n",
    "    out[key] = {}\n",
    "    \n",
    "    # first deal with equitorial and then galactic\n",
    "    subkeys = ['equitorial', 'galactic']\n",
    "    cnames = [('ra', 'dec', 'icrs'), ('l', 'b', 'galactic')]\n",
    "    for subkey, c in zip(subkeys, cnames):\n",
    "        \n",
    "        c1, c2, frame = c\n",
    "        c1_units, c2_units = f'{c1}_units', f'{c2}_units'\n",
    "        \n",
    "        if subkey in t1[key] and subkey in t2[key]:\n",
    "            out[key][subkey] = t1[key][subkey]\n",
    "            curr_coords = np.array([SkyCoord(val[c1], val[c2], unit=(val[c1_units], val[c2_units]), frame=frame) for val in t1[key][subkey]])\n",
    "            for coord in t2[key][subkey]:\n",
    "                coorddict = {c1:coord[c1],\n",
    "                             c2:coord[c2],\n",
    "                             'unit':(coord[c1_units], coord[c2_units]),\n",
    "                             'frame': frame\n",
    "                            }\n",
    "                skycoord = SkyCoord(**coorddict)\n",
    "                if skycoord not in curr_coords:\n",
    "                    out[key][subkey].append(coord)\n",
    "                else:\n",
    "                    idx = np.where(skycoord == curr_coords)[0][0] # we only need the first value\n",
    "                    ref = out[key][subkey][idx]['reference']\n",
    "                    if not isinstance(ref, list):\n",
    "                        out[key][subkey][idx]['reference'] = [ref]\n",
    "                    \n",
    "                    if not isinstance(coord['reference'], list):\n",
    "                        coord['reference'] = [coord['reference']]\n",
    "                    \n",
    "                    newdata = list(np.unique(out[key][subkey][idx]['reference']+coord['reference']))\n",
    "                    out[key][subkey][idx]['reference'] = newdata\n",
    "\n",
    "        elif subkey in t1[key]:\n",
    "            out[key][subkey] = t1[key][subkey]\n",
    "\n",
    "        elif subkey in t2[key]:\n",
    "            out[key][subkey] = t2[key][subkey]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7501e3d-b0ac-41e0-ab45-d24b9c32c36a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _merge_filter_alias(t1, t2, out):\n",
    "    '''\n",
    "    Combine the filter alias lists across the transient objects\n",
    "    '''\n",
    "    \n",
    "    key = 'filter_alias'\n",
    "    \n",
    "    out[key] = deepcopy(t1[key])\n",
    "    keys1 = {filt['filter_key'] for filt in t1[key]}\n",
    "    for filt in t2[key]:\n",
    "        if filt['filter_key'] not in keys1:\n",
    "            out[key].append(filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc808998-6ee9-41bb-bee3-5aff31fe7a1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _merge_schema_version(t1, t2, out):\n",
    "    '''\n",
    "    Just keep whichever schema version is greater\n",
    "    '''\n",
    "    key = 'schema_version/value'\n",
    "    if int(t1[key]) > int(t2[key]):\n",
    "        out['schema_version'] = deepcopy(t1['schema_version'])\n",
    "    else:\n",
    "        out['schema_version'] = deepcopy(t2['schema_version'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ad85c4-26fb-4b3f-bb40-27dce7ea946e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _merge_photometry(t1, t2, out):\n",
    "    '''\n",
    "    Combine photometry sources\n",
    "    '''\n",
    "    \n",
    "    key = 'photometry'\n",
    "    \n",
    "    out[key] = deepcopy(t1[key])\n",
    "    \n",
    "    idx = int(list(out[key].keys())[-1][-1])+1\n",
    "    telescopes = np.array([phot['telescope'] for phot in out[key].values() if 'telescope' in phot])\n",
    "    refs = np.array([phot['reference'] for phot in out[key].values() if 'reference' in phot])\n",
    "    for phot in t2[key].values():\n",
    "\n",
    "        if len(telescopes) > 0 and 'telescope' in phot and phot['telescope'] in telescopes:\n",
    "            i = np.where(phot['telescope'] == telescopes)[0][0]\n",
    "            toappend = out[key][f'phot_{i}']\n",
    "        elif len(refs) > 0 and 'reference' in phot and phot['reference'] in refs:\n",
    "            i = np.where(phot['reference'] == refs)[0][0]\n",
    "            toappend = out[key][f'phot_{i}']\n",
    "        else:\n",
    "            # nothing with this telescope has been added\n",
    "            out[key][f'phot_{idx}'] = phot\n",
    "            idx += 1\n",
    "            continue\n",
    "            \n",
    "        # if the code has gotten here we need to append to an existing list of photometry\n",
    "        for point in phot['flux']:\n",
    "            if point not in toappend['flux']:\n",
    "                toappend['flux'].append(point)\n",
    "            else:\n",
    "                if not isinstance(toappend['reference'], list):\n",
    "                    toappend['reference'] = [toappend['reference']]\n",
    "                    \n",
    "                if not isinstance(phot['reference'], list):\n",
    "                    phot['reference'] = [phot['reference']]\n",
    "                \n",
    "                if phot['reference'] not in toappend['reference']:    \n",
    "                    newdata = list(np.unique(toappend['reference']+phot['reference']))\n",
    "                    toappend['reference'] = newdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0767353-795a-4109-ad8b-6053fc147f91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _merge_spectra(t1, t2, out):\n",
    "    '''\n",
    "    Combine spectra sources\n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1679edda-526e-464d-b3ec-7a904830f5f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _merge_class(t1, t2, out):\n",
    "    '''\n",
    "    Combine the classification attribute\n",
    "    '''\n",
    "    key = 'classification'\n",
    "    out[key] = deepcopy(t1[key])\n",
    "    classes = np.array([item['object_class'] for item in out[key]])\n",
    "    for item in t2[key]:\n",
    "        if item['object_class'] in classes:\n",
    "            i = np.where(item['object_class'] == classes)[0][0]\n",
    "            if int(item['confidence']) > int(out[key][i]['confidence']):\n",
    "                out[key][i]['confidence'] = item['confidence'] # we are now more confident\n",
    "            \n",
    "            if not isinstance(out[key][i]['reference']):\n",
    "                out[key][i]['reference'] = [out[key][i]['reference']]\n",
    "            \n",
    "            if not isinstance(item['reference']):\n",
    "                item['reference'] = [item['reference']]\n",
    "            \n",
    "            newdata = list(np.unique(out[key][i]['reference']+item['reference']))\n",
    "            out[key][i]['reference'] = newdata\n",
    "            \n",
    "        else:\n",
    "            out[key].append(item)\n",
    "            \n",
    "    # now that we have all of them we need to figure out which one is the default\n",
    "    maxconf = max(out[key], key=lambda d: d['confidence'])  \n",
    "    for item in out[key]:\n",
    "        if item == maxconf:\n",
    "            item['default'] = True\n",
    "        else:\n",
    "            item['default'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274b1579-11ea-40e6-91b7-a09946c530e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _merge_epoch(t1, t2, out):\n",
    "    '''\n",
    "    Combine epoch data across two transients and write it to \"out\"\n",
    "    '''\n",
    "    key = 'epoch'\n",
    "    subkeys = ['date_explosion', 'date_peak', 'date_discovery']\n",
    "    \n",
    "    out[key] = {}\n",
    "    \n",
    "    for subkey in subkeys:\n",
    "        if subkey in t1[key] and subkey in t2[key]:\n",
    "            out[key][subkey] = t1[key][subkey]\n",
    "            values = np.array([val['value'] for val in out[key][subkey]])\n",
    "            for item in t2[key][subkey]:\n",
    "                if item['value'] in values:\n",
    "                    i = np.where(item['value'] == values)[0][0]\n",
    "                    if not isinstance(out[key][subkey][i]['reference'], list):\n",
    "                        out[key][subkey][i]['reference'] = [out[key][subkey][i]['reference']]\n",
    "                    if not isinstance(item['reference'], list):\n",
    "                        item['reference'] = [item['reference']]\n",
    "                    \n",
    "                    out[key][subkey][i]['reference'] = list(np.unique(out[key][subkey][i]['reference']+item['reference']))\n",
    "                else:\n",
    "                    out[key][subkey].append(item)\n",
    "                        \n",
    "        elif subkey in t1[key]:\n",
    "            out[key][subkey] = t1[key][subkey]\n",
    "        \n",
    "        elif subkey in t2[key]:\n",
    "            out[key][subkey] = t2[key][subkey]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4383eae-947a-4055-aca6-b2d2851c917d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _merge_distance(t1, t2, out):\n",
    "    '''\n",
    "    Combine distance information for these two transients\n",
    "    '''\n",
    "    key = 'distance'\n",
    "    subkeys = ['redshift', 'luminosity_distance', 'dispersion_measure']\n",
    "    out[key] = {}\n",
    "    for subkey in subkeys:\n",
    "        if subkey in t1[key] and subkey in t2[key]:\n",
    "            out[key][subkey] = t1[key][subkey]\n",
    "            values = np.array([val['value'] for val in out[key][subkey]])\n",
    "            for item in t2[key][subkey]:\n",
    "                if item['value'] in values:\n",
    "                    i = np.where(item['value'] == values)[0][0]\n",
    "                    if not isinstance(out[key][subkey][i]['reference'], list):\n",
    "                        out[key][subkey][i]['reference'] = [out[key][subkey][i]['reference']]\n",
    "                    if not isinstance(item['reference'], list):\n",
    "                        item['reference'] = [item['reference']]\n",
    "                    \n",
    "                    out[key][subkey][i]['reference'] = list(np.unique(out[key][subkey][i]['reference']+item['reference']))\n",
    "                else:\n",
    "                    out[key][subkey].append(item)\n",
    "        \n",
    "        elif subkey in t1[key]:\n",
    "            out[key][subkey] = t1[key][subkey]\n",
    "        \n",
    "        elif subkey in t2[key]:\n",
    "            out[key][subkey] = t2[key][subkey]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80da9bf2-f980-4fd3-b546-6c6d9cb85932",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# THIS IS WHERE THE ACTUAL SOFTWARE WILL START!!!!\n",
    "# define an output dictionary\n",
    "out = {}\n",
    "\n",
    "# find the keys that are \n",
    "merge_keys = list(t1.keys() & t2.keys()) # in both t1 and t2 so we need to merge these keys\n",
    "only_in_t1 = list(t1.keys() - t2.keys()) # only in t1\n",
    "only_in_t2 = list(t2.keys() - t1.keys()) # only in t2\n",
    "\n",
    "# now let's handle the merge keys\n",
    "for key in merge_keys:\n",
    "    \n",
    "    # reference_alias is special\n",
    "    # we ALWAYS should combine these two\n",
    "    if key == 'reference_alias':\n",
    "        out[key] = t1[key]\n",
    "        if t1[key] != t2[key]:\n",
    "            # only add t2 values if they aren't already in it\n",
    "            bibcodes = {ref['name'] for ref in t1[key]}\n",
    "            for val in t2[key]:\n",
    "                if val['name'] not in bibcodes:\n",
    "                    out[key].append(val)\n",
    "        continue\n",
    "        \n",
    "    # we can skip this merge process and just add the values from t1 \n",
    "    # if they are equal. We should still add the new reference though!\n",
    "    if t1[key] == t2[key]:\n",
    "        # set the value\n",
    "        # we don't need to worry about references because this will\n",
    "        # only be true if the reference is also equal!\n",
    "        out[key] = t1[key]\n",
    "        continue\n",
    "        \n",
    "    # There are some special keys that we are expecting\n",
    "    if key == 'name':\n",
    "        _merge_names(t1, t2, out)               \n",
    "    elif key == 'coordinate':\n",
    "        _merge_coords(t1, t2, out)\n",
    "    elif key == 'epoch':\n",
    "        _merge_epoch(t1, t2, out)\n",
    "    elif key == 'distance':\n",
    "        _merge_distance(t1, t2, out)\n",
    "    elif key == 'filter_alias':\n",
    "        _merge_filter_alias(t1, t2, out)\n",
    "    elif key == 'schema_version':\n",
    "        _merge_schema_version(t1, t2, out)\n",
    "    elif key == 'photometry':\n",
    "        _merge_photometry(t1, t2, out)\n",
    "    elif key == 'spectra':\n",
    "        _merge_spectra(t1, t2, out)\n",
    "    elif key == 'classification':\n",
    "        _merge_class(t1, t2, out)\n",
    "    else:\n",
    "        # this is an unexpected key! \n",
    "        # Throw a warning and only keep the old stuff\n",
    "        warnings.warn(f'{key} was not expected! Only keeping the old information!')\n",
    "        out[key] = deepcopy(t1[key])\n",
    "\n",
    "# and now combining out with the stuff only in t1 and t2\n",
    "out = out | dict(t1[only_in_t1]) | dict(t2[only_in_t2])\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0a8376-448b-4669-ab65-16a8fa9bc946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122ffda8-3168-4fa0-a388-e9d29088eb7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
